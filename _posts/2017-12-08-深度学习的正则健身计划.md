---
layout: post
comments: true
title: 预告-深度学习的正则健身计划
published: true
---

深度学习，和所有机器学习算法一样，也有着bias-variance的平衡问题。Bias是指模型基于不准确的假设而给出了错误答案，通常由于under-fit产生，模型的表达力还不够强大；Variance指模型由于训练数据中的小扰动过于敏感产生的错误，通常由于over-fit产生，模型太过复杂而失去了训练集以外数据的泛化能力。

深度学习的模型发展到今天，神经元层数越来越深不见底，层间连接也越来越走位飘忽。如此复杂的模型常常会陷入埋头炼丹多日却表现孱弱的尴尬局面。这篇文章我们来总结下各路老中医怎样给神经网络用多种正则手段定制健身计划，让神经网络模型更健康，更强大。



## Shared Weights


## Early Stopping


## Dropout


## Batch Normalization


## Gradient Clipping


## L1 and L2 Norm on Weights


## Dataset Augmentation


## Multi-task Learning


## Sparse Representation


## Bagging Ensemble


## Adversarial Training


## Tangent Distance/Prop?


