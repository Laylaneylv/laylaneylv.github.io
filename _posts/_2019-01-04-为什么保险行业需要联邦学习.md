---
layout: post
comments: true
title: 为什么保险行业需要联邦学习
published: true
---


联邦学习起源于谷歌2016年发表在NIPS的一篇[文章](https://pmpml.github.io/PMPML16/papers/PMPML16_paper_20.pdf)和2017年发表的[博客](https://ai.googleblog.com/2017/04/federated-learning-collaborative.html)。其大意是谷歌要训练自家安卓系统的Gboard输入法模型，但又不希望把用户敏感的键盘数据上传到自家服务器（我在看着你呢搜狗同学）。所以与其让用户上传数据到云端服务器训练模型，谷歌选择让用户在自己的智能手机上单独训练一个模型（感谢各家芯片厂商的neural engine），然后把千万用户每个人的黑盒参数的模型上传去谷歌的云端服务器进行融合，更新官方模型，然后再推送还给用户。这样一方面避免了用户敏感数据的传输和存储，一方面又利用了用户智能手机的计算能力（即是edge computing）而大大减轻了集中服务器的计算压力。

联邦学习的概念在发表的时候，谷歌虽然提到了数据隐私，但论文核心重点是模型如何在手机上传带宽受限的情况下进行传输，而用户模型的融合也只是用了简单有效的参数平均。这么做的原因是因为工程上类似的想法在**分布式机器学习**中已经被探讨了很多，slave-master结构被广泛采用，参数服务器大放异彩，模型参数以致训练过程中的梯度都可以在同步或非同步的方式下计算和传递。联邦学习的关注重点于是放在了没有严格分布式计算环境、上传带宽受限、海量用户作为slave下的“工程实现”。

一方面随着社会对数据隐私的日益关注和政府越来越多相关政策的出台，正在疯狂积累数据和逐渐创造价值的企业们被数据合规束缚了手脚；另一方面随着分工细化和市场竞争的加剧，同行业和非同行业之间都虎视眈眈盯着对方盘子里的蛋糕而把自己的数据视若珍宝，数据孤岛妨碍了行业整体合作互利的可能性。大家都在寻找一个既能数据合规又能说服持份者合作共赢的彻底释放数据潜力的方法。这个时候联邦学习对数据隐私的作用就很快被人们认识到了，“联邦学习”这四个字也从一个谷歌产品的工程实现升级成为一个**鼓励行业间数据分享共赢又尊重个体数据隐私的概念和解决方案**。



