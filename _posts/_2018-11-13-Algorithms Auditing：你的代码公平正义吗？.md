---
layout: post
comments: true
title: Algorithms Auditing：你的代码公平正义吗？
published: true
---

## “古板守旧”的传统行业？

进入保险行业做数据科学这近一年，最大的感触就是规管太多，手脚束缚。

保险的整条业务线其实很符合一家数据公司的商业模式：根据用户需求推销保险产品，用户投保，核保，定制保险产品内容和定价，售后服务，用户损失赔付，新保单续约等等；每一个环节都可能产生数据，训练模型，定制化和自动化。

所以还等什么呢？Shut up and show me the AUC，撸起袖子干呗。刚入职的时候我就是这么想的。然后发现审计部门和法律部门的同事分分钟就坐在旁边虎视眈眈。每个月几封规管政策邮件，时不时发一封可爱的钓鱼邮件测试警惕性。你的数据哪来的，怎么存的，有敏感信息吗，能出境吗？你的模型怎么解释，为什么薇薇安-翠花的保费就是比约翰-狗蛋贵，有性别歧视和年龄歧视的风险吗？etc etc...

几轮之后就想摔键盘了。码农的莫名优越感不由得膨胀出来：你知道我们曾经一个神之调参帮老板省了多少钱么，你知道我们曾经一个优雅模型帮老板多卖了多少产品么，你知道我们曾经一个顺滑自动化系统帮老板少雇了多少低端劳动力么，你知道...

## 算法真的最牛b？

直到最近，看到一些新闻，我才认真问自己一些无关算法准确率的问题：

>2016年的血友病贴吧被卖事件及一起因轻信竞价排名推荐的莆田系医院导致患滑膜肉瘤病者死亡的事件令百度的竞价排名丑闻再次成为社会焦点。

>10月21日，一篇名为《估值175亿的旅游独角兽，是一座僵尸和水军构成的鬼城？》在社交网络广为流传，该篇文章作者乎睿数据团队直指在线旅游网站马蜂窝存在点评大量造假的情况，包括从其他网站如大众点评、携程等抓取相关点评，及自建团队撰写虚拟点评。

>为庆祝iG夺冠，王思聪于2018年11月6日通过微博发布冠军之月庆祝抽奖活动。这次王思聪113人的中奖名单，有112人的性别为女性，男性只有1人。这里说的是微博资料的性别。另外苹果手机占这113人的78%，而苹果手机在中国市场的占有率不到10%。

身为一个技术宅，第一反应还是同情了一下同行。搜索引擎排名要无痕加入竞价权重可能还是需要一些模型的。写过爬虫的人也都知道跟反爬虫的网站干起来是多么惨烈，虚拟点评更是有些创意了都。至于王思聪的抽奖，微博CEO解释是为了防止被机器号抽中，想必这背后也是各种训练调参。可是这么多次事件出来，给人的感觉还是赢了技术，输了人格。

应该怪法律团队吗？可貌似也确实没违法。测试团队呢？所有按钮流程都跑过了是真的没bug。模型团队呢？A/B testing也都通过了效果很不错呢。

所以我想，可能我们缺的，是一个算法或者模型的审计功能：**Algorithms Auditor**.

## 算法审计when and who？

亚马逊推荐商品，Spotify推荐歌曲，乃至今日头条推荐新闻，这些可能只需要商家做**内部算法审计**，因为这些场景“不道德”的风险很低；模型表现差，顶多用户不喜欢，不玩了，商家少赚点钱。

至于“旅游独角兽”爬数据这件事，要去审计的大概是那些投资人们，这时候可以要有一些**民间第三方算法审计咨询公司**出现了。

而公共抽奖平台，银行放贷评估，保险公司核保，可能也包括搜索引擎结果，这些传统上就应该接受非常严格的政府规管的行业要接入算法和模型，就需要几个**公信力十足的官方算法审计大佬**了。

## 算法怎么审计?

算法怎么审计？这是核心问题也是我等技术宅最感兴趣的部分。

### Audit on Results

直接把算法产生的批量结果拿来审计可能是最直接简单的方法，一些最简单的数据挖掘和可视化已经能说明很多问题。网友发现王思聪抽奖结果全是女性和iPhone用户，就足以质疑抽奖的公平性。

### Audit on Models

如果是一些规则系统，或是简单的线性模型，模型本身就可能可以直接用来审计了。规则系统不用多说，性别歧视年龄歧视的规则绝对扎眼。微博的去除机器号的系统假如是个线性模型，也大概可以直接计算出不同特征的权重，很容易发现安卓系统和男性的参数权重彻底主宰了判别机器号的模型。

对于非线性的黑箱模型，可解释性就成了一个关键问题。一个思路是如Hinton的[Distilling a Neural Network Into a Soft Decision Tree](https://arxiv.org/abs/1711.09784)，将神经网络等复杂模型近似为一个决策树模型，从而理解模型的决策逻辑。

### Audit on Features

对于黑箱模型，另一个方向是在预测时的特征权重上下功夫。当前已经有不少学术研究在从这个角度试图解释黑箱模型，如[LIME](https://github.com/marcotcr/lime)试图在一个局部区域内用线性模型拟合原先的黑箱模型计算特定预测结果的特征权重，或者[SHAP](https://github.com/slundberg/shap)使用shapley value将各种特征排列组合然后计算特征权重。

## 所以，你的代码公平正义吗？

随着机器学习模型越来越复杂和不透明，随着金融保险等强规管行业也在把目光投向人工智能，也随着中国互联网从业人员们越来越鸡贼，我们是该认真谈谈算法解释性、公平性和从业者职业道德的时候了。这不是改一改目标优化函数那么简单。

**算法审计，Algorithms Auditing**，可能是解决很多问题的关键。一方面规管了现有无底线的互联网玩法让我等在诸如抢随机数额红包的时候的心态平和一些，一方面也给金融保险等强规管行业一针使用人工智能的强心剂。

所以，你的代码公平正义吗？反正王思聪的奖我是没抽中。如果你就是在微博做机器人识别的兄弟，欢迎你开源你的代码然后艾特我下哦。